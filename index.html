<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Industrial Red-Triggered Analyzer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
  <style>
    @keyframes slide-in-right {
      from { transform: translateX(100%); opacity: 0; }
      to { transform: translateX(0); opacity: 1; }
    }
    .animate-slide-in-right {
      animation: slide-in-right 0.4s ease-out;
    }

    @keyframes pulse-scan {
      0%, 100% { box-shadow: 0 0 0 0 rgba(255, 0, 0, 0.5); }
      50% { box-shadow: 0 0 25px 25px rgba(255, 0, 0, 0); }
    }
    .animate-pulse-scan {
      animation: pulse-scan 2s infinite;
    }
  </style>
</head>
<body class="bg-gray-900 text-white min-h-screen p-4 font-mono">

  <!-- Toasts -->
  <div id="toast-container" class="fixed top-4 right-4 z-50 space-y-2"></div>

  <header class="text-center mb-6 animate-fade-in">
    <h1 class="text-4xl font-extrabold text-red-500 tracking-wide animate-bounce">Industrial Red-Triggered Analyzer</h1>
    <p class="text-gray-400 mt-1 text-sm italic">Powered by AI - Detecting Banana Ripeness in Real-time</p>
  </header>

  <main class="flex flex-col lg:flex-row gap-6 max-w-7xl mx-auto items-start">

    <!-- Camera Section -->
    <div class="w-full max-w-[640px] space-y-4">
      <div class="relative aspect-video border-4 border-red-600 rounded-lg overflow-hidden w-full animate-pulse-scan">
        <video id="video" autoplay playsinline class="absolute w-full h-full object-cover rounded-lg"></video>
        <canvas id="canvas" class="absolute w-full h-full hidden"></canvas>
      </div>
      <button id="switch-camera-btn" class="bg-indigo-600 hover:bg-indigo-700 text-white px-4 py-2 rounded shadow w-full sm:w-auto">ðŸ”„ Switch Camera</button>
    </div>

    <!-- Sidebar -->
    <div class="w-full lg:w-[320px] space-y-6">

      <!-- Predictions -->
      <section class="bg-gray-800 p-4 rounded border border-red-400 shadow-lg">
        <h2 class="text-xl font-semibold text-red-400 mb-2">ðŸ§  Predictions</h2>
        <ul id="prediction-list" class="space-y-2 text-sm"></ul>
      </section>

      <!-- History -->
      <section class="bg-gray-800 p-4 rounded border border-green-500 max-h-[250px] overflow-y-auto shadow-inner">
        <h2 class="text-xl font-semibold text-green-400 mb-2">ðŸ“œ Detection History</h2>
        <ul id="history-list" class="space-y-2 text-xs"></ul>
      </section>
    </div>
  </main>

  <script>
    let currentCamera = 'environment';
    let stream = null;
    let track = null;
    let detectionInProgress = false;
    let latestImageBlob = null;

    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");

    const switchBtn = document.getElementById("switch-camera-btn");
    const toastContainer = document.getElementById("toast-container");
    const predictionList = document.getElementById("prediction-list");
    const historyList = document.getElementById("history-list");

    const VALID_CLASSES = ['freshripe', 'freshunripe', 'overripe', 'ripe', 'rotten', 'unripe'];

    // Start Camera
    async function startCamera(facingMode = 'environment') {
      if (stream) stream.getTracks().forEach(t => t.stop());

      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode, width: 640, height: 480 },
          audio: false
        });

        video.srcObject = stream;
        track = stream.getVideoTracks()[0];

        canvas.classList.add("hidden");
        video.classList.remove("hidden");

      } catch (err) {
        alert("Camera error: " + err.message);
      }
    }

    // Switch Camera
    switchBtn.addEventListener("click", () => {
      currentCamera = currentCamera === "user" ? "environment" : "user";
      startCamera(currentCamera);
    });

    // Red Color Detection + Auto Capture
    setInterval(() => {
      if (detectionInProgress || !track) return;

      const width = video.videoWidth;
      const height = video.videoHeight;
      if (width === 0 || height === 0) return;

      canvas.width = width;
      canvas.height = height;
      ctx.drawImage(video, 0, 0, width, height);

      const frame = ctx.getImageData(0, 0, width, height).data;
      let redPixels = 0;
      for (let i = 0; i < frame.length; i += 4) {
        const r = frame[i], g = frame[i + 1], b = frame[i + 2];
        if (r > 150 && g < 80 && b < 80) redPixels++;
      }

      const redRatio = redPixels / (width * height);
      if (redRatio > 0.02) {
        detectionInProgress = true;
        captureAndDetect();
      }

    }, 1000);

    // Auto Capture & Detect
    async function captureAndDetect() {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      canvas.classList.remove("hidden");
      video.classList.add("hidden");

      const blob = await new Promise(res => canvas.toBlob(res, "image/jpeg"));
      latestImageBlob = blob;

      const reader = new FileReader();
      reader.onloadend = async () => {
        const base64Image = reader.result.replace(/^data:image\/jpeg;base64,/, '');

        const res = await fetch("https://serverless.roboflow.com/fruit-ripening-process/2?api_key=Ur7hXZ8pVPs9vpScKv7w", {
          method: "POST",
          headers: { "Content-Type": "application/x-www-form-urlencoded" },
          body: base64Image
        });

        const data = await res.json();
        drawPredictions(data.predictions);
        updatePredictionList(data.predictions);
        updateHistory(data.predictions);
        speakDetections(data.predictions);
        showAlerts(data.predictions);

        const relevant = data.predictions.filter(pred => VALID_CLASSES.includes(pred.class));
        if (relevant.length > 0) downloadResults(relevant);

        setTimeout(() => {
          detectionInProgress = false;
          startCamera(currentCamera);
        }, 3000);
      };

      reader.readAsDataURL(blob);
    }

    // Draw Prediction Boxes
    function drawPredictions(preds) {
      preds.forEach(pred => {
        const { x, y, width, height, class: label, confidence } = pred;
        ctx.strokeStyle = "#00FF00";
        ctx.lineWidth = 2;
        ctx.strokeRect(x - width / 2, y - height / 2, width, height);
        ctx.fillStyle = "#00FF00";
        ctx.font = "16px Arial";
        ctx.fillText(`${label} (${(confidence * 100).toFixed(1)}%)`, x - width / 2, y - height / 2 - 8);
      });
    }

    function updatePredictionList(preds) {
      predictionList.innerHTML = '';
      preds.forEach(pred => {
        const li = document.createElement("li");
        li.className = "bg-gray-700 px-3 py-1 rounded border-l-4 border-red-400 animate-slide-in-right";
        li.textContent = `${pred.class.toUpperCase()} - ${(pred.confidence * 100).toFixed(1)}%`;
        predictionList.appendChild(li);
      });
    }

    function updateHistory(preds) {
      const time = new Date().toLocaleTimeString();
      preds.forEach(pred => {
        const li = document.createElement("li");
        li.className = "bg-gray-700 px-3 py-1 rounded border-l-4 border-green-500";
        li.textContent = `[${time}] ${pred.class.toUpperCase()} - ${(pred.confidence * 100).toFixed(1)}%`;
        historyList.prepend(li);
        if (historyList.children.length > 50) historyList.removeChild(historyList.lastChild);
      });
    }

    function speakDetections(preds) {
      preds.forEach(pred => {
        const msg = new SpeechSynthesisUtterance(`${pred.class} detected, ${(pred.confidence * 100).toFixed(0)} percent`);
        msg.lang = "en-US";
        speechSynthesis.speak(msg);
      });
    }

    function showAlerts(preds) {
      preds.forEach(pred => {
        const toast = document.createElement("div");
        toast.className = "bg-blue-700 text-white px-4 py-2 rounded shadow-lg animate-slide-in-right";
        toast.textContent = `ðŸ”” ${pred.class.toUpperCase()} - ${(pred.confidence * 100).toFixed(1)}%`;
        toastContainer.appendChild(toast);
        setTimeout(() => {
          toast.classList.add("opacity-0");
          setTimeout(() => toast.remove(), 500);
        }, 3000);
      });
    }

    async function downloadResults(preds) {
      const historyText = preds.map(pred =>
        `${pred.class.toUpperCase()} - ${(pred.confidence * 100).toFixed(1)}%`
      ).join("\n");

      const zip = new JSZip();
      zip.file("detection-result.txt", historyText);
      zip.file("captured-image.jpg", latestImageBlob);

      const zipBlob = await zip.generateAsync({ type: "blob" });
      const a = document.createElement("a");
      a.href = URL.createObjectURL(zipBlob);
      a.download = `detection-${Date.now()}.zip`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      URL.revokeObjectURL(a.href);
    }

    // Start camera on load
    startCamera(currentCamera);
  </script>
</body>
</html>
